---
title: "P8105_hw3_ys3394"
author: "Yifan Su"
date: "10/10/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rnoaa)
library(ggridges)
library(patchwork) 
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

#### Do some exploration of the dataset "instacart".

```{r}
data("instacart")
```

**A Short description**

* This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

* This instacart online grocery shopping dataset has information about orders of users on the instacart, with each row represents the data of one product of an order. 

* Key variables of user and order are -- user ID, order day and order hour. They are other variables about items and products, including aisle, department and their ID numbers. It's worth noticing that there are many aisles in a department, and products with different aisles and departments ID are distinct.


Number of ailes, and show aisles that most items ordered from.

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Make a plot shows number of items and those greater than 10000 items ordered.

```{r}
instacart %>% 
  count(aisle) %>%
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>%  # convert aisle to a factor variable, then we can use the function fct_reorder to adjust order.
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1)) +
  labs(
    title = "Aisles with more than 10000 items ordered",
    x = "Aisles' names",
    y = "Number of orders",
    caption = "Data from instacart online grocery shopping dataset 2017"
  )
```

Make a table showing the three most popular items in each of the aisles.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(
    rank = min_rank(desc(n))
  ) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable(digits = 2)
```

Make a table of the mean hour of the day of two items in a week.

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour,
    names_prefix = "mean_order_hour_of_day_"
  ) %>% 
  t() %>% 
  knitr::kable(digits = 2)
```

# Comment on each results


## Problem 2

```{r}
chf_df =
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute_day",
    values_to = "activity_counts",
    names_prefix = "activity_"
    ) %>% 
  mutate(
    minute_day = as.integer(minute_day),
    week = as.factor(week),
    day_id = as.factor(day_id),
    day = as.factor(day),
    weekday_weekend = case_when(
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      day %in% c("Saturday", "Sunday") ~ "weekend"),
    weekday_weekend = as.factor(weekday_weekend),
    day = forcats::fct_relevel(day, "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
    )
```

#Describe results

**Traditional analyses of accelerometer data focus on the total activity over the day**

```{r}
chf_df_2 =
  chf_df %>% 
  group_by(week, day) %>% 
  summarize(sum_counts = sum(activity_counts)) %>% 
  pivot_wider(
    names_from = day,
    values_from = sum_counts
  ) %>% 
  mutate(sum_week = sum(Monday:Sunday)) %>% 
  knitr::kable(digits = 2)
```

# show trends

**Accelerometer data allows the inspection activity over the course of the day**

```{r warning=FALSE}
  chf_df %>% 
  ggplot(aes(x = minute_day, y = activity_counts, color = day)) +
  geom_smooth(se = FALSE) +
  labs( 
    title = "Inspection activity over day",
    x = "Hours",
    y = "Activity counts",
    caption = "Data from instacart online grocery shopping dataset 2017"
  ) +
   viridis::scale_color_viridis(
    name = "day",
    discrete =  TRUE
   ) +
  scale_y_continuous(trans = "sqrt") +
  scale_x_continuous(breaks = c(1, 240, 480, 720, 960, 1200, 1440), 
                     labels = c("0h","4h", "8h", "12h", "16h", "20h", "24h"))+
  theme_minimal()
```

#Describe in words any patterns or conclusions you can make based on this graph


## Problem 3

#### Do some exploration of the dataset "NOAA".

```{r}
data("ny_noaa")
```

#To that end, write a short description of the dataset, noting the size and structure of the data, describing some key variables, and indicating the extent to which missing data is an issue. Then, do or answer the following (commenting on the results of each)

**Data cleaning**

```{r}

```

